project_name: "Knative"
benchmark_name: "Generic Eventing Benchmark"
description: "Measure latency and throughput of an eventing component."

### ATTENTION: This is a sample benchmark config. Do not attempt to create or
# update this benchmark with the mako tool. See
test/performance/sample-dev.config for an example of a real benchmark config.

# Any changes made below this comment must be copied to all
# benchmark config files in test/performance/benchmarks.

# Define the name and type for x-axis of run charts
input_value_info: {
  value_key: "t"
  label: "time"
  type: TIMESTAMP
}

# Note: value_key is stored repeatedly and should be very short (ideally one or two characters).
metric_info_list: {
  value_key: "pl"
  label: "publish-latency"
}
metric_info_list: {
  value_key: "pe"
  label: "publish-errors"
}
metric_info_list: {
  value_key: "st"
  label: "send-throughput"
}
metric_info_list: {
  value_key: "dl"
  label: "deliver-latency"
}
metric_info_list: {
  value_key: "de"
  label: "deliver-errors"
}
metric_info_list: {
  value_key: "dt"
  label: "deliver-throughput"
}
metric_info_list: {
  value_key: "pet"
  label: "publish-failure-throughput"
}
metric_info_list: {
  value_key: "det"
  label: "deliver-failure-throughput"
}
